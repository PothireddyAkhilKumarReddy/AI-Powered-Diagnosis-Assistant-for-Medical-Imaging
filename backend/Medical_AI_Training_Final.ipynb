{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83c\udfe5 Medical AI Bot - High Accuracy Training (DenseNet121) \ud83c\udfe5\n",
                "\n",
                "This notebook is designed to train a **highly accurate** medical image classifier.\n",
                "We use **DenseNet121**, a powerful architecture for X-ray analysis, and automatically download high-quality data from Kaggle.\n",
                "\n",
                "### \ud83d\ude80 Step 1: Initialize & Authenticate\n",
                "1.  Upload your **`kaggle.json`** file below (Get it from your [Kaggle Account](https://www.kaggle.com/account) -> API -> Create New Token)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q tf-keras kaggle\n",
                "import os\n",
                "from google.colab import files\n",
                "\n",
                "# Force TensorFlow to use Keras 2 (legacy) format\n",
                "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
                "\n",
                "# Upload kaggle.json\n",
                "if not os.path.exists('kaggle.json'):\n",
                "    print(\"Upload your kaggle.json file:\")\n",
                "    files.upload()\n",
                "\n",
                "# Configure Kaggle\n",
                "!mkdir -p ~/.kaggle\n",
                "!cp kaggle.json ~/.kaggle/\n",
                "!chmod 600 ~/.kaggle/kaggle.json\n",
                "print(\"\u2705 Kaggle Configured Successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udce5 Step 2: Download & Prepare Data\n",
                "We will download TWO datasets to ensure we have enough diversity:\n",
                "1.  **COVID-19 Radiography Database** (Good for COVID/Normal)\n",
                "2.  **Chest X-Ray Prediction** (Good for Pneumonia)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\u23f3 Downloading Datasets... Please wait.\")\n",
                "\n",
                "# 1. Download COVID-19 Radiography Database\n",
                "if not os.path.exists('covid19-radiography-database.zip'):\n",
                "    !kaggle datasets download -d tawsifurrahman/covid19-radiography-database\n",
                "    !unzip -q covid19-radiography-database.zip\n",
                "    print(\"\u2705 COVID-19 Database Downloaded.\")\n",
                "\n",
                "# 2. Download Pneumonia Dataset\n",
                "if not os.path.exists('chest-xray-pneumonia.zip'):\n",
                "    !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
                "    !unzip -q chest-xray-pneumonia.zip\n",
                "    print(\"\u2705 Pneumonia Database Downloaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "import random\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Setup Dataset Directory\n",
                "DATASET_DIR = 'dataset'\n",
                "if os.path.exists(DATASET_DIR):\n",
                "    shutil.rmtree(DATASET_DIR)\n",
                "os.makedirs(DATASET_DIR)\n",
                "\n",
                "CLASSES = ['Normal', 'COVID-19', 'Pneumonia']\n",
                "for c in CLASSES:\n",
                "    os.makedirs(os.path.join(DATASET_DIR, c), exist_ok=True)\n",
                "\n",
                "print(\"\ud83d\udcc2 Organizing Data...\")\n",
                "\n",
                "# --- 1. Process COVID-19 Images ---\n",
                "covid_src = os.path.join('COVID-19_Radiography_Dataset', 'COVID', 'images')\n",
                "dst = os.path.join(DATASET_DIR, 'COVID-19')\n",
                "files = [f for f in os.listdir(covid_src) if f.lower().endswith('.png')]\n",
                "# Use ALL COVID images (usually ~3600)\n",
                "for f in tqdm(files, desc=\"Copying COVID\"):\n",
                "    shutil.copy(os.path.join(covid_src, f), os.path.join(dst, f))\n",
                "\n",
                "# --- 2. Process Normal Images ---\n",
                "# We limit Normal images to match COVID count roughly to avoid imbalance\n",
                "normal_src = os.path.join('COVID-19_Radiography_Dataset', 'Normal', 'images')\n",
                "dst = os.path.join(DATASET_DIR, 'Normal')\n",
                "files = [f for f in os.listdir(normal_src) if f.lower().endswith('.png')]\n",
                "selected_files = random.sample(files, min(len(files), 4000)) # improved balance\n",
                "for f in tqdm(selected_files, desc=\"Copying Normal\"):\n",
                "    shutil.copy(os.path.join(normal_src, f), os.path.join(dst, f))\n",
                "\n",
                "# --- 3. Process Pneumonia Images ---\n",
                "pneum_src = os.path.join('chest_xray', 'train', 'PNEUMONIA')\n",
                "dst = os.path.join(DATASET_DIR, 'Pneumonia')\n",
                "files = [f for f in os.listdir(pneum_src) if f.lower().endswith('.jpeg')]\n",
                "# Pneumonia dataset is large (~3800), take 4000 to match\n",
                "selected_files = files[:4000] \n",
                "for f in tqdm(selected_files, desc=\"Copying Pneumonia\"):\n",
                "    shutil.copy(os.path.join(pneum_src, f), os.path.join(dst, f))\n",
                "\n",
                "print(\"\\n\u2705 Data Preparation Complete!\")\n",
                "for c in CLASSES:\n",
                "    print(f\"   {c}: {len(os.listdir(os.path.join(DATASET_DIR, c)))} images\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83e\udde0 Step 3: Build & Train Model (DenseNet121)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, optimizers\n",
                "from tensorflow.keras.applications import DenseNet121\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
                "import numpy as np\n",
                "\n",
                "# Configuration\n",
                "IMG_SIZE = (224, 224)\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 30\n",
                "DATASET_DIR = \"dataset\"\n",
                "CLASSES = ['COVID-19', 'Normal', 'Pneumonia'] # Match old index order if possible, or print it.\n",
                "\n",
                "AUTOTUNE = tf.data.AUTOTUNE\n",
                "\n",
                "def get_label(file_path):\n",
                "    parts = tf.strings.split(file_path, os.path.sep)\n",
                "    return parts[-2] == CLASSES\n",
                "\n",
                "def decode_img(img):\n",
                "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
                "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
                "    img = tf.image.resize(img, IMG_SIZE)\n",
                "    return img\n",
                "\n",
                "def process_path(file_path):\n",
                "    label = get_label(file_path)\n",
                "    img = tf.io.read_file(file_path)\n",
                "    img = decode_img(img)\n",
                "    return img, label\n",
                "\n",
                "def get_dataset(directory, validation_split=0.2):\n",
                "    list_ds = tf.data.Dataset.list_files(str(directory + '/*/*'), shuffle=False)\n",
                "    list_ds = list_ds.shuffle(10000, seed=42)\n",
                "    \n",
                "    val_size = int(len(list_ds) * validation_split)\n",
                "    train_ds = list_ds.skip(val_size)\n",
                "    val_ds = list_ds.take(val_size)\n",
                "    \n",
                "    return train_ds, val_ds\n",
                "\n",
                "train_ds, val_ds = get_dataset(DATASET_DIR)\n",
                "\n",
                "def augment(image, label):\n",
                "    image = tf.image.random_flip_left_right(image)\n",
                "    image = tf.image.random_brightness(image, 0.2)\n",
                "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
                "    return image, label\n",
                "\n",
                "# Set up Train Generator\n",
                "train_generator = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
                "train_generator = train_generator.cache()\n",
                "train_generator = train_generator.shuffle(buffer_size=1000)\n",
                "train_generator = train_generator.map(augment, num_parallel_calls=AUTOTUNE)\n",
                "train_generator = train_generator.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
                "\n",
                "# Set up Validation Generator\n",
                "val_generator = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
                "val_generator = val_generator.batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)\n",
                "\n",
                "print(\"Dataset pipeline ready (optimized with tf.data).\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_model():\n",
                "    base_model = DenseNet121(\n",
                "        weights='imagenet',\n",
                "        include_top=False,\n",
                "        input_shape=IMG_SIZE + (3,)\n",
                "    )\n",
                "    \n",
                "    # Unfreeze the last block for fine-tuning\n",
                "    base_model.trainable = True\n",
                "    for layer in base_model.layers[:-40]: # Fine-tune last 40 layers\n",
                "        layer.trainable = False\n",
                "        \n",
                "    model = models.Sequential([\n",
                "        base_model,\n",
                "        layers.GlobalAveragePooling2D(),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Dropout(0.5),\n",
                "        layers.Dense(512, activation='relu'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Dropout(0.3),\n",
                "        layers.Dense(3, activation='softmax') # 3 classes\n",
                "    ])\n",
                "    \n",
                "    model.compile(\n",
                "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
                "        loss='categorical_crossentropy',\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    return model\n",
                "\n",
                "model = build_model()\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks\n",
                "checkpoint = ModelCheckpoint(\n",
                "    'best_model.h5',\n",
                "    monitor='val_accuracy',\n",
                "    save_best_only=True,\n",
                "    mode='max',\n",
                "    verbose=1\n",
                ")\n",
                "early_stop = EarlyStopping(monitor='val_accuracy', patience=8, verbose=1, restore_best_weights=True)\n",
                "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
                "\n",
                "print(\"\ud83d\ude80 Starting Training...\")\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    epochs=EPOCHS,\n",
                "    validation_data=val_generator,\n",
                "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udcca Step 4: Evaluate & Save"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "import seaborn as sns\n",
                "\n",
                "# 1. Plot Accuracy/Loss\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history.history['accuracy'], label='Train')\n",
                "plt.plot(history.history['val_accuracy'], label='Validation')\n",
                "plt.title('Accuracy')\n",
                "plt.legend()\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history.history['loss'], label='Train')\n",
                "plt.plot(history.history['val_loss'], label='Validation')\n",
                "plt.title('Loss')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# 2. Confusion Matrix\n",
                "print(\"Generating Classification Report...\")\n",
                "val_generator.reset()\n",
                "preds = model.predict(val_generator)\n",
                "y_pred = np.argmax(preds, axis=1)\n",
                "y_true = val_generator.classes\n",
                "\n",
                "print(classification_report(y_true, y_pred, target_names=CLASSES))\n",
                "\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save Final Model\n",
                "model.save('model.h5')\n",
                "print(\"\u2705 Model Saved as 'model.h5'\")\n",
                "\n",
                "# Download\n",
                "from google.colab import files\n",
                "files.download('model.h5')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}